{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24ef8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:05:59.430 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8176</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/v3/concepts/server#how-to-guides</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:05:59.430 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8176\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/v3/concepts/server#how-to-guides\u001b[0m for more information on running a dedicated Prefect server.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:06:04.931 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'beautiful-quokka'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'beautiful-quokka'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'FlightDelayETL-Pipeline'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:06:04.931 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'beautiful-quokka'\u001b[0m - Beginning flow run\u001b[35m 'beautiful-quokka'\u001b[0m for flow\u001b[1;35m 'FlightDelayETL-Pipeline'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:06:04.935 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'beautiful-quokka'</span> - Pipeline started\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:06:04.935 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'beautiful-quokka'\u001b[0m - Pipeline started\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flights: 29193782\n",
      "Weather: 91\n",
      "Airports: 82808\n",
      "+-----------+------+------------------------------------------------+----+------------------------------------------------+-------------------+--------------+-------------+-------------+--------+--------+\n",
      "|flight_date|origin|origin_name                                     |dest|dest_name                                       |scheduled_dep      |temperature_2m|precipitation|windspeed_10m|ArrDelay|DepDelay|\n",
      "+-----------+------+------------------------------------------------+----+------------------------------------------------+-------------------+--------------+-------------+-------------+--------+--------+\n",
      "|2018-01-23 |ABY   |Southwest Georgia Regional Airport              |ATL |Hartsfield Jackson Atlanta International Airport|2018-01-23 12:02:00|NULL          |NULL         |NULL         |-8.0    |-5.0    |\n",
      "|2018-01-24 |ABY   |Southwest Georgia Regional Airport              |ATL |Hartsfield Jackson Atlanta International Airport|2018-01-24 12:02:00|NULL          |NULL         |NULL         |-6.0    |-5.0    |\n",
      "|2018-01-25 |ABY   |Southwest Georgia Regional Airport              |ATL |Hartsfield Jackson Atlanta International Airport|2018-01-25 12:02:00|NULL          |NULL         |NULL         |-2.0    |-9.0    |\n",
      "|2018-01-26 |ABY   |Southwest Georgia Regional Airport              |ATL |Hartsfield Jackson Atlanta International Airport|2018-01-26 12:02:00|NULL          |NULL         |NULL         |-11.0   |-12.0   |\n",
      "|2018-01-27 |ABY   |Southwest Georgia Regional Airport              |ATL |Hartsfield Jackson Atlanta International Airport|2018-01-27 14:00:00|NULL          |NULL         |NULL         |-1.0    |-5.0    |\n",
      "|2018-01-28 |ABY   |Southwest Georgia Regional Airport              |ATL |Hartsfield Jackson Atlanta International Airport|2018-01-28 12:02:00|NULL          |NULL         |NULL         |22.0    |NULL    |\n",
      "|2018-01-29 |ABY   |Southwest Georgia Regional Airport              |ATL |Hartsfield Jackson Atlanta International Airport|2018-01-29 12:02:00|NULL          |NULL         |NULL         |-1.0    |2.0     |\n",
      "|2018-01-30 |ABY   |Southwest Georgia Regional Airport              |ATL |Hartsfield Jackson Atlanta International Airport|2018-01-30 12:02:00|NULL          |NULL         |NULL         |-9.0    |-9.0    |\n",
      "|2018-01-31 |ABY   |Southwest Georgia Regional Airport              |ATL |Hartsfield Jackson Atlanta International Airport|2018-01-31 12:02:00|NULL          |NULL         |NULL         |NULL    |-9.0    |\n",
      "|2018-01-03 |ATL   |Hartsfield Jackson Atlanta International Airport|ABY |Southwest Georgia Regional Airport              |2018-01-03 10:37:00|NULL          |NULL         |NULL         |22.0    |24.0    |\n",
      "+-----------+------+------------------------------------------------+----+------------------------------------------------+-------------------+--------------+-------------+-------------+--------+--------+\n",
      "only showing top 10 rows\n",
      "Final row count: 28416515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:07:46.405 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'beautiful-quokka'</span> - Pipeline completed successfully\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:07:46.405 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'beautiful-quokka'\u001b[0m - Pipeline completed successfully\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:07:46.708 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'beautiful-quokka'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:07:46.708 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'beautiful-quokka'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from prefect import flow\n",
    "from prefect.logging import get_run_logger\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import (\n",
    "        col, to_date, concat_ws, lpad, try_to_timestamp, lit\n",
    "    )\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "@flow(name=\"FlightDelayETL-Pipeline\")\n",
    "def flight_delay_pipeline():\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Pipeline started\")\n",
    "\n",
    "    # =========================\n",
    "    # importing cell\n",
    "    # =========================\n",
    "\n",
    "    \n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(\"FlightDelayETL\")\n",
    "        .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "    # =========================\n",
    "    # data loading cell\n",
    "    # =========================\n",
    "\n",
    "    flights_df = spark.read.parquet(\"data/source/flight_all\")\n",
    "\n",
    "    weather_df = (\n",
    "        spark.read\n",
    "        .option(\"multiline\", \"true\")\n",
    "        .option(\"mode\", \"PERMISSIVE\")\n",
    "        .json(\"data/source/weather_all\")\n",
    "    )\n",
    "\n",
    "    airports_df = (\n",
    "        spark.read\n",
    "        .option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .csv(\"data/source/airport-codes.csv\")\n",
    "    )\n",
    "\n",
    "    print(\"Flights:\", flights_df.count())\n",
    "    print(\"Weather:\", weather_df.count())\n",
    "    print(\"Airports:\", airports_df.count())\n",
    "\n",
    "    # =========================\n",
    "    # cleaning flights\n",
    "    # =========================\n",
    "\n",
    "    \n",
    "\n",
    "    flights_clean = (\n",
    "        flights_df\n",
    "        .filter(col(\"Cancelled\") == False)\n",
    "        .withColumn(\"flight_date\", to_date(col(\"FlightDate\")))\n",
    "        .withColumn(\n",
    "            \"scheduled_dep\",\n",
    "            try_to_timestamp(\n",
    "                concat_ws(\n",
    "                    \" \",\n",
    "                    col(\"flight_date\").cast(\"string\"),\n",
    "                    lpad(col(\"CRSDepTime\").cast(\"string\"), 4, \"0\")\n",
    "                ),\n",
    "                lit(\"yyyy-MM-dd HHmm\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # airports cleaning\n",
    "    # =========================\n",
    "\n",
    "    airports_fixed = (\n",
    "        airports_df\n",
    "        .filter(col(\"iata_code\").isNotNull())\n",
    "        .withColumn(\"lat_str\", trim(split(col(\"coordinates\"), \",\")[0]))\n",
    "        .withColumn(\"lon_str\", trim(split(col(\"coordinates\"), \",\")[1]))\n",
    "        .withColumn(\"latitude\", col(\"lat_str\").cast(\"double\"))\n",
    "        .withColumn(\"longitude\", col(\"lon_str\").cast(\"double\"))\n",
    "        .select(\n",
    "            col(\"iata_code\"),\n",
    "            col(\"name\"),\n",
    "            col(\"latitude\"),\n",
    "            col(\"longitude\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    orig_airports = airports_fixed.select(\n",
    "        col(\"iata_code\").alias(\"origin\"),\n",
    "        col(\"latitude\").alias(\"origin_lat\"),\n",
    "        col(\"longitude\").alias(\"origin_lon\"),\n",
    "        col(\"name\").alias(\"origin_name\")\n",
    "    )\n",
    "\n",
    "    dest_airports = airports_fixed.select(\n",
    "        col(\"iata_code\").alias(\"dest\"),\n",
    "        col(\"latitude\").alias(\"dest_lat\"),\n",
    "        col(\"longitude\").alias(\"dest_lon\"),\n",
    "        col(\"name\").alias(\"dest_name\")\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # weather cleaning\n",
    "    # =========================\n",
    "\n",
    "    weather_clean = (\n",
    "        weather_df\n",
    "        .withColumnRenamed(\"latitude\", \"weather_lat\")\n",
    "        .withColumnRenamed(\"longitude\", \"weather_lon\")\n",
    "        .select(\n",
    "            \"weather_lat\",\n",
    "            \"weather_lon\",\n",
    "            posexplode(\"hourly.time\").alias(\"idx\", \"weather_time\"),\n",
    "            col(\"hourly.temperature_2m\").alias(\"temperature_2m\"),\n",
    "            col(\"hourly.precipitation\").alias(\"precipitation\"),\n",
    "            col(\"hourly.windspeed_10m\").alias(\"windspeed_10m\")\n",
    "        )\n",
    "        .withColumn(\"weather_time\", to_timestamp(\"weather_time\"))\n",
    "        .withColumn(\"weather_hour\", date_trunc(\"hour\", col(\"weather_time\")))\n",
    "        .select(\n",
    "            \"weather_lat\",\n",
    "            \"weather_lon\",\n",
    "            \"weather_hour\",\n",
    "            col(\"temperature_2m\")[col(\"idx\")].alias(\"temperature_2m\"),\n",
    "            col(\"precipitation\")[col(\"idx\")].alias(\"precipitation\"),\n",
    "            col(\"windspeed_10m\")[col(\"idx\")].alias(\"windspeed_10m\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # enrichment joins\n",
    "    # =========================\n",
    "\n",
    "    flights_enriched = (\n",
    "        flights_clean\n",
    "        .join(broadcast(orig_airports), \"origin\", \"left\")\n",
    "        .join(broadcast(dest_airports), \"dest\", \"left\")\n",
    "    )\n",
    "\n",
    "    flights_final = (\n",
    "        flights_enriched\n",
    "        .withColumn(\"scheduled_hour\", date_trunc(\"hour\", col(\"scheduled_dep\")))\n",
    "        .join(\n",
    "            weather_clean,\n",
    "            (flights_enriched.origin_lat == weather_clean.weather_lat) &\n",
    "            (flights_enriched.origin_lon == weather_clean.weather_lon) &\n",
    "            (col(\"scheduled_hour\") == weather_clean.weather_hour),\n",
    "            \"left\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    final_df = flights_final.select(\n",
    "        \"flight_date\",\n",
    "        \"origin\",\n",
    "        \"origin_name\",\n",
    "        \"dest\",\n",
    "        \"dest_name\",\n",
    "        \"scheduled_dep\",\n",
    "        \"temperature_2m\",\n",
    "        \"precipitation\",\n",
    "        \"windspeed_10m\",\n",
    "        \"ArrDelay\",\n",
    "        \"DepDelay\"\n",
    "    )\n",
    "\n",
    "    final_df.show(10, truncate=False)\n",
    "    print(\"Final row count:\", final_df.count())\n",
    "\n",
    "    # =========================\n",
    "    # write parquet\n",
    "    # =========================\n",
    "\n",
    "    (\n",
    "        final_df\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .partitionBy(\"flight_date\")\n",
    "        .parquet(\"data/final/flights_enriched.parquet\")\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # DuckDB load & analytics\n",
    "    # =========================\n",
    "\n",
    "    \n",
    "\n",
    "    con = duckdb.connect(database=\"flights_analysis.duckdb\", read_only=False)\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE flights_enriched AS\n",
    "        SELECT * FROM read_parquet('data/final/flights_enriched.parquet/**/*.parquet')\n",
    "    \"\"\")\n",
    "\n",
    "    avg_delay_by_origin = con.execute(\"\"\"\n",
    "        SELECT \n",
    "            origin,\n",
    "            origin_name,\n",
    "            COUNT(*) AS flights,\n",
    "            AVG(DepDelay) AS avg_dep_delay,\n",
    "            AVG(ArrDelay) AS avg_arr_delay\n",
    "        FROM flights_enriched\n",
    "        WHERE DepDelay IS NOT NULL\n",
    "        GROUP BY origin, origin_name\n",
    "        ORDER BY avg_dep_delay DESC\n",
    "        LIMIT 15\n",
    "    \"\"\").df()\n",
    "\n",
    "    logger.info(\"Pipeline completed successfully\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    flight_delay_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
